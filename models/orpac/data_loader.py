""" A uniform interface to request images."""
import os
import copy
import glob
import tqdm
import pickle
import compile_features
import numpy as np

from PIL import Image
from config import NetConf
from collections import namedtuple
from feature_utils import setIsFg, setBBoxRects, setClassLabel, oneHotEncoder


class ORPAC:
    """Load the training data generated by ds2sim.

    Each training element comprises one image with a corresponding meta file.
    The meta file holds information about the label of each pixel, as well as
    the object ID of each pixel to distinguish them as well.

    The ctor expects a NetConf tuple as the sole argument. Inside that tuple,
    only the following attributes are relevant:

    Args:
        conf (NetConf): simulation parameters.
        conf.seed (int):
            Seed for Numpy random generator.
        conf.samples (int):
            Number of samples to use for each label. Use all if set to None.

    """
    # Define the MetaData container for this data set.
    MetaData = namedtuple(
        'MetaData',
        'img y filename mask_fg mask_bbox mask_cls mask_valid mask_objid_at_pix'
    )

    def __init__(self, conf):
        # Sanity check.
        assert isinstance(conf, NetConf)
        assert isinstance(conf.ft_dim, tuple)
        assert len(conf.ft_dim) == 2
        assert isinstance(conf.ft_dim[0], int)
        assert isinstance(conf.ft_dim[1], int)
        self.conf = conf

        # Set the random number generator.
        if conf.seed is not None:
            np.random.seed(conf.seed)

        # Load the features and labels.
        self.ft_dim = conf.ft_dim
        dims, label2name, metas = self.loadRawData(conf.ft_dim)

        # Images must have three dimensions. The second and third dimensions
        # correspond to the height and width, respectively, whereas the first
        # dimensions corresponds to the colour channels and must be either 1
        # (gray scale) or 3 (RGB).
        dims = np.array(dims, np.uint32)
        assert len(dims) == 3 and dims.shape[0] in [1, 3]
        self.image_dims = dims

        # Store the pre-processed labels.
        self.metas = metas
        self.label2name = label2name
        p = np.random.permutation(len(metas))[:conf.samples]

        # Case 1: no data -> print warning, Case 2: only single file -> add
        # it to training and test set irrespective of training ratio, Case 3:
        # partition the data into test/training sets.
        if len(metas) == 0:
            print('Warning: data set is empty')
        self.handles = p

        # Initialise the ofs in the current epoch for training/test data.
        self.epoch_ofs = 0
        self.reset()

    def printSummary(self):
        """Print a summary to screen."""
        print('Data Set Summary:')
        print(f'  Samples: {len(self.handles):,}')

        if self.label2name is not None:
            tmp = [_[1] for _ in sorted(self.label2name.items())]
            tmp = str.join(', ', tmp)
        else:
            tmp = 'None'
        d, h, w = self.image_dims
        print(f'  Image  : {d} x {h} x {w}')
        print(f'  Labels : {tmp}')

    def reset(self):
        """Reset the epoch.

        After this, a call to getNextBatch will start served images from the
        start of the epoch again.
        """
        self.epoch_ofs = 0

    def int2name(self):
        """ Return the mapping between machine/human readable labels"""
        return dict(self.label2name)

    def lenOfEpoch(self):
        """Return number of samples in entire full epoch."""
        return len(self.handles)

    def imageDimensions(self):
        """Return image dimensions, eg (3, 64, 64)"""
        return np.array(self.image_dims, np.uint32)

    def getMeta(self, uuid: int):
        if not (0 <= uuid < len(self.meta)):
            return None
        return copy.deepcopy(self.meta[uuid])

    def getFeatureSize(self):
        return tuple(self.ft_dim)

    def loadRawData(self, ft_dim):
        """Return feature and label vector for data set of choice.

        Returns:
            dims: Array[3]
                Image shape in CHW format, eg (3, 512, 512).
            int: dict[int:str]
                A LUT to translate machine labels to human readable strings.
                For instance {0: 'None', 1: 'Cube 0', 2: 'Cube 1'}.
            meta: N-List[MetaData]
                MetaData tuple for each sample.
        """
        # Compile a list of JPG images in the source folder. Then verify that
        # a) each is a valid JPG file and b) all images have the same size.
        fnames = self.findTrainingFiles(self.conf.samples)
        height, width = self.checkImageDimensions(fnames)

        # If the features have not been compiled yet, do so now.
        self.compileMissingFeatures(fnames, ft_dim)

        # Load the compiled training data alongside each image.
        return self.loadTrainingData(fnames, width, height, ft_dim)

    def next(self):
        """Return next training image and labels.

        Returns:
            meta: Named tuple
            UUID: int
                UUID to query meta information via `getMeta`.
        """
        try:
            uuid = self.handles[self.epoch_ofs]
            self.epoch_ofs += 1

            return self.metas[uuid], uuid
        except IndexError:
            return None, None, None

    def checkImageDimensions(self, fnames):
        dims = {Image.open(fname + '.jpg').size for fname in fnames}
        if len(dims) == 1:
            width, height = dims.pop()
            return height, width

        print('\nError: found different images sizes: ', dims)
        assert False, 'Images do not all have the same size'

    def findTrainingFiles(self, N):
        # Find all training images and strip off the '.jpg' extension. Abort if
        # there are no files.
        if os.path.isdir(self.conf.path):
            fnames = glob.glob(f'{self.conf.path}/*.jpg')
            fnames = [_[:-4] for _ in sorted(fnames)][:N]
            if len(fnames) == 0:
                print(f'\nError: No images in {self.conf.path}\n')
                raise FileNotFoundError(self.conf.path)
        elif os.path.isfile(self.conf.path):
            if self.conf.path[-4:].lower() != '.jpg':
                print(f'\nError: <{self.conf.path}> must be JPG file\n')
                raise FileNotFoundError(self.conf.path)
            fnames = [self.conf.path[:-4]]
        else:
            print(f'\nError: <{self.conf.path}> is not a valid file or path\n')
            raise FileNotFoundError(self.conf.path)
        return fnames

    def compileMissingFeatures(self, fnames, ft_dim):
        # Find out which images have no training output yet.
        missing = []
        for fname in fnames:
            try:
                tmp = pickle.load(open(fname + '-compiled.pickle', 'rb'))
                assert ft_dim in tmp.keys()
            except (pickle.UnpicklingError, FileNotFoundError, AssertionError):
                missing.append(fname)

        # Compile the missing training output.
        if len(missing) > 0:
            progbar = tqdm.tqdm(missing, desc=f'Compiling Features', leave=False)
            for fname in progbar:
                img = Image.open(fname + '.jpg').convert('RGB')
                img = np.array(img)
                out = compile_features.generate(fname, img, ft_dim)
                pickle.dump(out, open(fname + '-compiled.pickle', 'wb'))

    def loadTrainingData(self, fnames, im_width, im_height, ft_dim):
        im_shape = (3, im_height, im_width)

        num_cls = None
        all_meta = []
        all_x = np.zeros((len(fnames), *im_shape), np.uint8)

        # Load each image and associated features.
        for i, fname in enumerate(fnames):
            # Load image as RGB and convert to Numpy.
            img = np.array(Image.open(fname + '.jpg').convert('RGB'), np.uint8)
            img_chw = np.transpose(img, [2, 0, 1])
            assert img_chw.shape == im_shape

            # Store image in CHW format.
            all_x[i] = img_chw
            del img_chw

            # All pre-compiled features must use the same label map.
            data = pickle.load(open(fname + '-compiled.pickle', 'rb'))
            if num_cls is None:
                int2name = data['int2name']
                num_cls = len(int2name)
            assert int2name == data['int2name']

            # Crate the training output for the selected feature map size.
            meta = self.compileTrainingOutput(data[ft_dim], img, num_cls)

            # Collect the training data.
            all_meta.append(meta._replace(filename=fname))

        # Return image, network output, label mapping, and meta data.
        return im_shape, int2name, all_meta

    def compileTrainingOutput(self, training_data, img, num_classes):
        assert img.dtype == np.uint8 and img.ndim == 3 and img.shape[2] == 3

        # Populate the training output with the BBox data and one-hot-label.
        # Unpack pixel labels.
        label_ap = training_data['label_at_pixel']
        objID_ap = training_data['objID_at_pixel']
        bbox_rects = training_data['bboxes']
        assert label_ap.dtype == np.int32 and label_ap.ndim == 2
        assert 0 <= np.amin(label_ap) <= np.amax(label_ap) < num_classes

        # Allocate the array for the expected network outputs (one for each
        # feature dimension size).
        # fixme: remove hard coded numbers
        ft_dim = label_ap.shape
        y = np.zeros((1, 4 + 2 + num_classes, *ft_dim))

        # Compute binary mask that is 1 at every foreground pixel.
        isFg = np.zeros(ft_dim)
        isFg[np.nonzero(label_ap)] = 1

        # Insert BBox parameter and hot-labels into the feature tensor.
        y[0] = setBBoxRects(y[0], bbox_rects)
        y[0] = setIsFg(y[0], oneHotEncoder(isFg, 2))
        y[0] = setClassLabel(y[0], oneHotEncoder(label_ap, num_classes))

        meta = self.MetaData(
            img=img,
            y=y,
            filename=None,
            mask_fg=training_data['mask_fg'],
            mask_bbox=training_data['mask_bbox'],
            mask_valid=training_data['mask_valid'],
            mask_cls=training_data['mask_cls'],
            mask_objid_at_pix=objID_ap,
        )

        # Sanity check: masks must be binary with correct shape.
        for field in ['fg', 'bbox', 'cls', 'valid']:
            tmp = getattr(meta, 'mask_' + field)
            assert tmp.dtype == np.uint8, field
            assert tmp.shape == ft_dim, field
            assert set(np.unique(tmp)).issubset({0, 1}), field
        return meta
